{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "51f2e43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, sklearn, seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bee45609",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['A','B','C','B','A','A','C','C']\n",
    "y = ['A','B','B','A','A','A','C','B']\n",
    "actual = pd.Series(x)\n",
    "predicted = pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6267b2",
   "metadata": {},
   "source": [
    "## User-defined function to find classification report for multiple classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cb8c685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification_Report(actuals,predicteds):\n",
    "    \n",
    "    f1_scores = []\n",
    "    recalls = []\n",
    "    accuracys = []\n",
    "    precisions = []\n",
    "    \n",
    "    for i in actuals.unique():\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        \n",
    "        for actual,predicted in zip(actuals,predicteds):\n",
    "            if actual == i and predicted == i:\n",
    "                tp += 1\n",
    "                \n",
    "            elif actual != i and predicted == i:\n",
    "                fp += 1\n",
    "                \n",
    "            elif actual == i and predicted != i:\n",
    "                fn += 1\n",
    "            \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = tp/(tp+fp+fn) if (tp+fp+fn) > 0 else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        accuracys.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "    \n",
    "    return pd.DataFrame({'Precision':precisions,'Recall':recalls,'f1_score':f1_scores,'Accuracys':accuracys},\n",
    "                       index = actuals.unique())\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "427cce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Accuracys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision    Recall  f1_score  Accuracys\n",
       "A   0.750000  1.000000  0.857143   0.750000\n",
       "B   0.333333  0.500000  0.400000   0.250000\n",
       "C   1.000000  0.333333  0.500000   0.333333"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification_Report(actual,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c399d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.75      1.00      0.86         3\n",
      "           B       0.33      0.50      0.40         2\n",
      "           C       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.62         8\n",
      "   macro avg       0.69      0.61      0.59         8\n",
      "weighted avg       0.74      0.62      0.61         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(actual,predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca7e09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a73344",
   "metadata": {},
   "source": [
    "## Testing the function for iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f30cb30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "763a8b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c352becf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris['species'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2183c697",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris[['sepal_length','sepal_width','petal_length','petal_width']]\n",
    "y = iris['species']\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,\n",
    "                                            test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fd89087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f75a8aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "97cc5852",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrainpred = lr.predict(xtrain)\n",
    "ytestpred = lr.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e4194357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9714285714285714, 0.9777777777777777)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "accuracy_score(ytrain,ytrainpred),accuracy_score(ytest,ytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "94febe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmtest = confusion_matrix(ytest,ytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "419c3636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0,  0],\n",
       "       [ 0, 14,  0],\n",
       "       [ 0,  1, 15]], dtype=int64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmtest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877fd0a9",
   "metadata": {},
   "source": [
    "## Finding the metrics for ytest and ytestpred using user-defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2c906648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Accuracys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision  Recall  f1_score  Accuracys\n",
       "versicolor   0.933333  1.0000  0.965517   0.933333\n",
       "virginica    1.000000  0.9375  0.967742   0.937500\n",
       "setosa       1.000000  1.0000  1.000000   1.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification_Report(ytest,ytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eafdf888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        15\n",
      "  versicolor       0.93      1.00      0.97        14\n",
      "   virginica       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(ytest,ytestpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dda6573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
