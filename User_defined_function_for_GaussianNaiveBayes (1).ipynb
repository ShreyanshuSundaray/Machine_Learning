{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iris[['sepal_length','petal_length','sepal_width','petal_width']]\n",
    "y = iris['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,\n",
    "                                            test_size = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined functions to fit and predict as GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_NB_fit(x_train,y_train):\n",
    "    samples,features = x_train.shape   # Storing total num of rows as sample and columns as features\n",
    "    classes = np.unique(y_train)\n",
    "    n_classes = len(classes)\n",
    "\n",
    "    # Used dictionary to store the entries classwise\n",
    "    cls_priors = {}\n",
    "    cls_means = {}\n",
    "    cls_var = {}\n",
    "\n",
    "    for i in classes:\n",
    "        x_cls = x_train[y_train == i]  #Storing Xtrain columns unique classwise of ytrain\n",
    "        cls_priors[i] = len(x_cls)/samples  #Finding the probability of each unique class\n",
    "        cls_means[i] = np.mean(x_cls, axis =0)  #Calculating the mean of each column claswise\n",
    "        cls_var[i] = np.var(x_cls, axis =0)   #Claculating variance in the same way\n",
    "\n",
    "# Creting a dictionary of all class outputs inside single key later it will be \n",
    "# easy to access in the prediction part using the keys.\n",
    "# each key stores the claculated values of each unique class together\n",
    "    output = {'class_priors': cls_priors, 'class_means':cls_means,\n",
    "              'class_variance':cls_var}\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "# Creating a function to predict the values using the parameter\n",
    "# model as object of gaussian_NB_fit function and the xtest value \n",
    "def gaussian_NB_predict(model,x_test):\n",
    "    cp = model['class_priors']    # Finding the values using keys of the object\n",
    "    cm = model['class_means']\n",
    "    cv = model['class_variance']\n",
    "\n",
    "    # then we have to find samples and cls length of xtest\n",
    "    t_sample = x_test.shape[0]\n",
    "    t_cls = len(cp)\n",
    "\n",
    "    prediction = []\n",
    "    \n",
    "    for i in range(t_sample):\n",
    "        posterior_probs = []\n",
    "\n",
    "        for j in cp:\n",
    "            prior = cp[j]  # Creating a loop and finding the prior,mean & var classwise\n",
    "            mean = cm[j]\n",
    "            var = cv[j]\n",
    "\n",
    "            # from the pdf formula Finding the exponent and likelihood value\n",
    "            exponent = -0.5 * np.sum((x_test.iloc[i] - mean) ** 2 / var)\n",
    "            likelihood = np.exp(exponent) / np.sqrt(2 * np.pi * var).prod()\n",
    "\n",
    "            posterior_prob = prior * likelihood\n",
    "            posterior_probs.append(posterior_prob)\n",
    "\n",
    "        prediction.append(list(cp.keys())[np.argmax(posterior_probs)])\n",
    "\n",
    "    return pd.Series(prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting and predicting values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit and prediction for user-defined function\n",
    "\n",
    "gnb_fit = gaussian_NB_fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrainpred = gaussian_NB_predict(gnb_fit,xtrain)\n",
    "ytestpred = gaussian_NB_predict(gnb_fit,xtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9583333333333334, 0.9666666666666667)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy_score(ytrain,ytrainpred), accuracy_score(ytest,ytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[40,  0,  0],\n",
       "        [ 0, 37,  3],\n",
       "        [ 0,  2, 38]], dtype=int64),\n",
       " array([[10,  0,  0],\n",
       "        [ 0, 10,  0],\n",
       "        [ 0,  1,  9]], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(ytrain,ytrainpred),confusion_matrix(ytest,ytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User defined function for classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classification_Report(actuals,predicteds):\n",
    "    \n",
    "    f1_scores = []\n",
    "    recalls = []\n",
    "    accuracys = []\n",
    "    precisions = []\n",
    "    \n",
    "    for i in actuals.unique():\n",
    "        tp = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        \n",
    "        for actual,predicted in zip(actuals,predicteds):\n",
    "            if actual == i and predicted == i:\n",
    "                tp += 1\n",
    "                \n",
    "            elif actual != i and predicted == i:\n",
    "                fp += 1\n",
    "                \n",
    "            elif actual == i and predicted != i:\n",
    "                fn += 1\n",
    "            \n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        accuracy = tp/(tp+fp+fn) if (tp+fp+fn) > 0 else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        accuracys.append(accuracy)\n",
    "        recalls.append(recall)\n",
    "        f1_scores.append(f1_score)\n",
    "    \n",
    "    return pd.DataFrame({'Precision':precisions,'Recall':recalls,'f1_score':f1_scores,'Accuracys':accuracys},\n",
    "                       index = actuals.unique())\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Accuracys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision  Recall  f1_score  Accuracys\n",
       "versicolor   0.909091     1.0  0.952381   0.909091\n",
       "virginica    1.000000     0.9  0.947368   0.900000\n",
       "setosa       1.000000     1.0  1.000000   1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification_Report(ytest,ytestpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Accuracys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.936709</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.950</td>\n",
       "      <td>0.938272</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Precision  Recall  f1_score  Accuracys\n",
       "versicolor   0.948718   0.925  0.936709   0.880952\n",
       "setosa       1.000000   1.000  1.000000   1.000000\n",
       "virginica    0.926829   0.950  0.938272   0.883721"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Classification_Report(ytrain,ytrainpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and prediction for gaussianNB\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.fit(xtrain,ytrain)\n",
    "ytrainpred_gnb = gnb.predict(xtrain)\n",
    "ytestpred_gnb = gnb.predict(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's check user-defined function and GaussianNB Algorithm both are working same or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[40,  0,  0],\n",
       "        [ 0, 37,  3],\n",
       "        [ 0,  2, 38]], dtype=int64),\n",
       " array([[10,  0,  0],\n",
       "        [ 0, 10,  0],\n",
       "        [ 0,  1,  9]], dtype=int64))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confusion matrix for GaussianNB Algorithm \n",
    "\n",
    "confusion_matrix(ytrain,ytrainpred_gnb),confusion_matrix(ytest,ytestpred_gnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[40,  0,  0],\n",
       "        [ 0, 37,  3],\n",
       "        [ 0,  2, 38]], dtype=int64),\n",
       " array([[10,  0,  0],\n",
       "        [ 0, 10,  0],\n",
       "        [ 0,  1,  9]], dtype=int64))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confusion matrix for user-defined function\n",
    "\n",
    "confusion_matrix(ytrain,ytrainpred),confusion_matrix(ytest,ytestpred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see Here Both Confusion matrix are giving same output so we can say that our function working properly as GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
